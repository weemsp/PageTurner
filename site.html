<html>
	<head>
		<title>Proposal</title>
	</head>
	<body>
		<h1>Problem Statement</h1>
			<p> Our team wants to introduce a new way of operating an individual’s device. Whether it be a laptop, desktop computer, tablet, 
			or mobile phone, our software should work on any device that can allow access to a camera. 
			At the base level, our software will be able to be used for e-reading, or reading on a device as opposed to a physical book. 
			Instead of the user having to use their hands or fingers to choose a book, flip a page, zoom in, etc., they will be able to 
			solely use eye movement and head gestures. For example, a head swing from the RIGHT to the LEFT could indicate flipping 
			forward a page. A double blink might be to select or “click” something. There are two main motivations for this project, 
			with the first being those who a physical handicap like dexterity issues or amputations making it difficult to navigate 
			point and click devices. The other motivation was for those people who just want an easy and comfortable way to read an 
			e-book on a device without using their hands every couple of seconds. We believe our software will be able to increase 
			productivity and personal happiness of the individuals who are struggling. Currently, we do not believe there to be 
			anything like this available to people. The only thing that is similar would be Tobii eyeX, which is an eye control software
			 for computers. However, Tobii uses their own camera which needs to be permanently mounted onto a computer, so this would 
			 not be ideal for tablets or smaller devices.
			</p>
		
		<h1>Methodology</h1>
			<h2>Data Collection</h2>
				<p> This project uses three need-finding techniques to address the questions of the problem statements:</p>
				
				<ul> 
					<li> Survey: An online survey that questions which way the user would like to be able to turn the page using motions from 
					their head and/or eyes. This can be expanded to ask successive questions about other features within the program.
					</li>
					
					<li> Interview: Speaking with people who may have a need for the program could be very insightful for our design.
					</li>
					
					<li> Observation: Observing individuals using our product could better help us understand what changes could be made to increase 
					user easy and efficiency.
					</li>
				</ul>
				
				<p> A survey is used to quickly receive feedback from potential users on ideas or design techniques within the program itself. 
				An interview will help by providing us with in-depth reasonings for why certain people believe certain features would be beneficial, 
				and how it would help them. Observation will be used more for testing the design of our program and ensuring it is easy to navigate 
				and set up as well as easy to understand and use without much external instructions.
				</p>
				
		<h1>Participant Category</h1>
			<p> Two types of participants are involved in the analysis: Primary User and Secondary User. The characteristics of 
			these participants, and the reason behind selecting them go as follows:
			</p>
			
			<ul>
				<li>Primary User: These participants will the those who have some sort of physical handicap that may hinder their ability to 
				properly navigate an e-reading device. The information gathered here will be used to better design the application around 
				those conditions, as the primary reasoning we want to create this program is to help those who have difficulties.
				</li>
				
				<li>  Secondary Users: This will be the information gathered from anyone else who wants to use our application for fun or 
				experiment around with facial control.
				</li>
			</ul>
			
		<h1>Further Details</h1>
			<h2> Survey </h2>
				<p> Surveys are an option because the speed of feedback will be helpful in making sure the right features are implemented 
				and can show us how to further develop the product. They are also convenient when compared to setting up and interview or 
				observation session. This would give those participants more flexibility of when they can help provide feedback for our program. 
				They also provide the ability to retrieve information from many respondents all in one place. This can help highlight which 
				features are widely appreciated or wanted, and which features would be good to change or new things to implement. 
				Surveys can also be created, modified, and reviewed rather easily to incorporate new questions based future changes. 
				The link to our first survey, which simply consists of one question to begin the development of our facial control features.
				</p>
				
			<h2> Interview </h2>
				<p>We believe that interviews will be the best way to find if our work will bring the most impact to people’s lives. 
				We will interview people with poor or little motor function in their arms and those people with amputations. We can 
				then use these responses to find out what participants would like to see implemented into the software, like changes 
				to set up, calibration, specific motions, new features, etc.
				</p>
				
			<h2> Observation </h2>
				<p>Observations, the final option we listed for gathering information, will be used to see general design flaws of our program. 
				If a user starts the program and gets stuck at the very opening page without knowing where to navigate to next, that will tell 
				us we need more on screen prompts, text boxes, or highlighted button needed to start calibration. Another example would be if the 
				user gets lost trying to perform a task, like zooming in on the screen. If they are stuck on this task for a while and can’t find 
				out how to do the desired task, that shows us we need to provide a more intuitive design that can be more easily navigated.
				</p>
				
				
		<h1> Prototyping </h1>
			<p>We are going to use digital prototyping. Because of the nature of the product we are designing, a digital prototype is the 
			only feasible option. The user Interface will be bare bones and we will only be testing for basic functionality. We will be 
			testing for eye tracking responsiveness and accuracy. A storyboard was faintly used at the very start to draft an idea of what 
			we were looking to develop. We do not believe any further prototyping of this type will be needed since the foundation program 
			is already made. For any larger changes that may be suggested, we can make a visual that help mentally see what it would look 
			like, then branch the program and continue coding. If the new model works and everyone is happy then that can be sent out for 
			testing. If either we do not like the new model or the participants are not happy with the changes, it can always be reverted 
			back to the previous version by simply going back before branching occurred, thus meaning virtual prototyping should be all that 
			is necessary for our project.
			</p>
			
		<h1> Prototype Fidelity</h1>
			<p> The program is going to have a number of features implemented in the future. Eye movement tracking, blink detection, and head 
			direction are some things that will be used to implement features such as turning pages, zooming in or out, and raising or lowering the brightness.
			</p>
		
		<h1> Implementation</h1>
			<p> A final version will have a completed and appealing User Interface with a wide variety of coloring and light features and font size 
			changes for people with poor eyesight. It will also allow for a wide array of e-book formats ranging from a PDF, word documents, and 
			official electronic publications. Our product will be on compatible on every reasonable platform and operating systems including mobile 
			devices. However small screen sizes on mobile could make an uncomfortable experience for the user. As camera depth of field is limited, 
			technical challenges would include compatibility between for all files and responsive eye detection. Some people will have low quality and 
			outdated webcams which will offer too low of a resolution for perfect eye detection. If low quality webcams are a major issue, we can use 
			machine learning tools such as TensorFlow to program the software to learn the difference between closed and open eyes on low quality images. 
			It would not require any backend servers and would locally off the user's computer. Optimization many be an issue for weaker and older hardware.
			</p>
			
		<h1> Conclusion </h1>
			<p>We believe the potential for our product to provide an increase in quality of life for certain individuals to be incredibly high. 
			With nothing like this being currently available on the market, our software is designed to appeal mostly to those with disabilities 
			which make it harder to operate point and click devices. However even with this specific niche audience in mind, the software can still 
			be easily used by any person who would want to try it out. With this is mind, it is a program that has a specific purpose in mind, but 
			an also be used by the masses. Being multi-purpose will help the product get off the ground and get users to start trying it out.
			The following is a link to the current working program.
			<br>
			
			<h3> <a href="https://weemsp.github.io/PageTurner"> PageTurner Program </a> </h3>
			
			</p>
			
		
	</body>
</html>
